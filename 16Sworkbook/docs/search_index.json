[["phyloseq.html", "6 Phyloseq 6.1 Import 6.2 Preprocess 6.3 Filtering", " 6 Phyloseq The phyloseq R package is a powerful framework for further analysis of microbiome data. We now demonstrate how to straightforwardly import the tables produced by the dada2 pipeline into phyloseq. 6.1 Import path &lt;- &quot;~/Desktop/microbiomeworkshop2022/&quot; ## Read in files seqtab &lt;- readRDS(file.path(path, &quot;results/seqtab_final.rds&quot;)) taxa &lt;- readRDS(file.path(path, &quot;results/taxa_final.rds&quot;)) 6.1.1 Exercise Read the metadata file into R, called info. Phyloseq needs the rownames of the metadata to match the sample names. How can you accomplish this? Before creating your phyloseq object, familiarize yourself with the metadata. Are there any other changes you need to make? It can sometimes be useful to clean up the sample names at this point - Illumina will add their own sample numbers to your sample names. You can do this by creating a new variable that doesnâ€™t contain the information Illumina added: info &lt;- info %&gt;% separate(SampleID, c(&quot;SampleID&quot;, &quot;temp&quot;), sep = &quot;_S&quot;) Make a phyloseq object: ps &lt;- phyloseq(otu_table(seqtab, taxa_are_rows=FALSE), sample_data(info), tax_table(taxa)) ps ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 1201 taxa and 24 samples ] ## sample_data() Sample Data: [ 24 samples by 5 sample variables ] ## tax_table() Taxonomy Table: [ 1201 taxa by 7 taxonomic ranks ] In order to look at the ASVs, we need to remove the sequences. ## Remove sequence names, rename to something manageable asv_names &lt;- vector(dim(otu_table(ps))[2], mode = &quot;character&quot;) for (i in 1:dim(otu_table(ps))[2]){ asv_names[i] &lt;- paste(&quot;ASV&quot;, i, sep = &quot;_&quot;) } taxa_names(ps) &lt;- asv_names colnames(otu_table(ps)) &lt;- asv_names rownames(tax_table(ps)) &lt;- asv_names You can see that the phyloseq object has an otu_table(ASV table), sample_data and tax_table. You can use functions tax_table(), sample_data() and otu_table() to access the data. 6.1.2 Exercise Take a look the following functions and find out what they do: subset_samples() subset_taxa() tax_glom() sample_sums() prune_samples() transform_sample_counts() psmelt() 6.2 Preprocess 6.2.1 Reads per sample In general, the first step in pre-processing is to check how many reads you have per sample and remove any samples if they failed. 6.2.2 Exercise Use either the rowSums() or colSums() function (or any other function of your choosing) to create a variable that contains the total number of reads per sample. Once you have this, create a data frame containing this information: counts &lt;- data.frame(as(sample_data(ps), &quot;data.frame&quot;), TotalReads = sums) head(counts) ## SampleID temp SubjectID Treatment Timepoint TotalReads ## 01MP-1_S1_L001 01MP-1 1_L001 PS25 A 1 64763 ## 01MP-2_S2_L001 01MP-2 2_L001 PS25 A 2 66378 ## 01MP-3_S3_L001 01MP-3 3_L001 PS25 A 3 65698 ## 03KW-1_S4_L001 03KW-1 4_L001 PS19 A 1 81586 ## 03KW-2_S5_L001 03KW-2 5_L001 PS19 A 2 55418 ## 03KW-3_S6_L001 03KW-3 6_L001 PS19 A 3 81770 6.2.3 Exercise Create a visualization of these results (something like the one below) and decide if any of the samples need to be removed. Other considerations: If there is a large amount of variation in the number of reads across samples (in general, more than 10-fold), you need to take steps to normalize the data. 6.3 Filtering Here, we filter out ASVs (amplicon sequence variants) using two criteria: abundance and prevalence. First, compute the prevalence of each ASV by defining prevalence as the number of samples in which a taxon appears at least once: prevdf &lt;- apply(X = otu_table(ps), MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2), FUN = function(x){sum(x &gt; 0)}) prevdf &lt;- data.frame(prevalence = prevdf, total_abundance = taxa_sums(ps), tax_table(ps)) Visualize prevalence: gg &lt;- ggplot(prevdf, aes(total_abundance, prevalence/nsamples(ps), colour = Phylum)) + geom_point(size = 2, alpha = 0.8) + scale_x_log10() + xlab(&quot;Total abundance&quot;) + ylab(&quot;Prevalence (fraction samples)&quot;) + theme_minimal() gg 6.3.1 Exercise Use this visualization to determine your filtering parameters and define them as prevalence_threshold and count_threshold. Add these parameters to your plot using the functions geom_hline() and geom_vline(). Define taxa to filter: keeptaxa &lt;- rownames(prevdf)[(prevdf$prevalence &gt; prevalence_threshold) &amp; (prevdf$total_abundance &gt; count_threshold)] Execute filter: Important to keep your unaltered data! psf &lt;- prune_taxa(keeptaxa, ps) Compute relative abundance (of both raw and filtered data): rel &lt;- transform_sample_counts(ps, function(x) x / sum(x)) relf &lt;- transform_sample_counts(psf, function(x) x / sum(x)) 6.3.2 Outlier Detection First, log transform your count data: pslog &lt;- transform_sample_counts(psf, function(x) log(1 + x)) Ordinate and get the eigenvalues for axes dimensions: ord &lt;- ordinate(pslog, method = &quot;PCoA&quot;, distance = &quot;bray&quot;) evals &lt;- ord$values$Eigenvalues 6.3.3 Exercise Create an ordination plot to check for any obvious outliers. Use the functions plot_ordination() and coord_fixed() to do this. Do you think any of these samples are outliers? How could you investigate further? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
