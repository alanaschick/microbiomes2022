---
title: "16s Microbiome Analysis Workshop"
author: "Alana Schick"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
link-citations: yes
description: This workbook contains workshop material for all three days.
---

# Welcome {-}

Placeholder


## Workshop Schedule {-}
### Day 1 {-}
### Day 2 {-}
### Day 3 {-}
## Important links {-}

<!--chapter:end:index.Rmd-->

# (PART) Day 1 {-}

# Pre-workshop

For simplicity, we will carry out this analysis from start to finish in R. Please ensure you have the latest version of R and RStudio. 
  
## Packages

Please install the following  R packages:
  
* dada2
* tidyverse
* phyloseq
* ShortRead
* Biostrings

Confirm that these are installed by loading them in R using `library(packagename)`.

## Data download

The data to use for the workshop can be downloaded from [here](https://www.dropbox.com/s/glw1aig4jsyxuem/raw_data.zip?dl=0).




<!--chapter:end:01-Preworkshop.Rmd-->


# Introduction

Placeholder


## Basics and Background
## Data
### Exercise

<!--chapter:end:02-Introduction.Rmd-->


# Removing Primers

Placeholder


## Identify Primers
## Remove Primers

<!--chapter:end:03-RemovingPrimers.Rmd-->

```{r setup4, include=FALSE} 
library(dada2)
library(tidyverse)
library(phyloseq)
library(Biostrings)
library(ShortRead)

# path <- "~/Desktop/microbiomeworkshop2022/rawdata"
# 
# fs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
# rs <- sort(list.files(path, pattern = "_R2_001.fastq.gz", full.names = TRUE))
# sample.names <- sapply(strsplit(fs, "_R"), `[`, 1)
# 
# 
# ftrim <- file.path(path, "trimmed", paste0(basename(sample.names), "_F_trimmed.fastq.gz"))
# rtrim <- file.path(path, "trimmed", paste0(basename(sample.names), "_R_trimmed.fastq.gz"))
```

# Filter

## Inspect

We begin by inspecting the quality profiles:

```{r}
plotQualityProfile(ftrim[1:2])
```

In gray-scale is a heat map of the frequency of each quality score at each base position. The mean quality score at each position is shown by the green line, and the quartiles of the quality score distribution by the orange lines. The red line shows the scaled proportion of reads that extend to at least that position (this is more useful for other sequencing technologies, as Illumina reads are typically all the same length, hence the flat red line).

The forward reads are good quality. We generally advise trimming the last few nucleotides to avoid less well-controlled errors that can arise there. These quality profiles do not suggest that any additional trimming is needed. We will truncate the forward reads at position 240 (trimming the last 10 nucleotides).

Now we visualize the quality profile of the reverse reads:

```{r}
plotQualityProfile(rtrim[1:2])
```

The reverse reads are of significantly worse quality, especially at the end, which is common in Illumina sequencing. This isn’t too worrisome, as DADA2 incorporates quality information into its error model which makes the algorithm robust to lower quality sequence, but trimming as the average qualities crash will improve the algorithm’s sensitivity to rare sequence variants. Based on these profiles, we will truncate the reverse reads at position 160 where the quality distribution crashes.

**IMPORTANT** Your reads must still overlap after truncation in order to merge them later!

### Exercise

Based on the expected size of the amplicon, what is the minimum truncation length that would still leave about 30 nucleotides of overlap?

## Filter and Trim

Assign the filenames for the filtered files:

```{r}
ffilt <- file.path(path, "filtered", paste0(basename(sample.names), "_F_filtered.fastq.gz"))
rfilt <- file.path(path, "filtered", paste0(basename(sample.names), "_R_filtered.fastq.gz"))
```

We’ll use standard filtering parameters: `maxN=0` (DADA2 requires no Ns), `truncQ=2`, `rm.phix=TRUE` and `maxEE=2`. The maxEE parameter sets the maximum number of “expected errors” allowed in a read, which is a better filter than simply averaging quality scores.

```{r}
out <- filterAndTrim(ftrim, ffilt, rtrim, rfilt, 
                     truncLen=c(240,160),
                     maxN=0, 
                     maxEE=c(2,2), 
                     truncQ=2, 
                     rm.phix=TRUE,
                     compress=TRUE, 
                     multithread=TRUE) # On Windows set multithread=FALSE
head(out)

## Save output
saveRDS(out, file.path("results", "filt_out.rds"))
```

Considerations for your own data:

The filtering parameters are starting points, not set in stone.

If you want to speed up downstream computation, consider tightening maxEE.

If too few reads are passing the filter, consider relaxing maxEE, perhaps especially on the reverse reads (eg. maxEE=c(2,5)), and reducing the truncLen to remove low quality tails.

Remember though, when choosing truncLen for paired-end reads you must maintain overlap after truncation in order to merge them later.

### Exercise

Determine what you think the optimal filtering parameters should be for this dataset. 


<!--chapter:end:04-Filter.Rmd-->

```{r setup5, include=FALSE} 
library(dada2)
library(tidyverse)
library(phyloseq)
library(Biostrings)
library(ShortRead)

path <- "~/Desktop/microbiomeworkshop2022/rawdata"

fs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
rs <- sort(list.files(path, pattern = "_R2_001.fastq.gz", full.names = TRUE))
sample.names <- sapply(strsplit(fs, "_R"), `[`, 1)


ftrim <- file.path(path, "trimmed", paste0(basename(sample.names), "_F_trimmed.fastq.gz"))
rtrim <- file.path(path, "trimmed", paste0(basename(sample.names), "_R_trimmed.fastq.gz"))
```

# Denoise


<!--chapter:end:05-Denoise.Rmd-->

